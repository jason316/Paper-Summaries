## Methods for Interpreting and Understanding Deep Neural networks

#### Gregoire Montavon, Wojciech Samek, Klaus-Robert Muller
 
This paper provides a tutorial like introduction to the problems of model interpretation and explanation. The authors define each of the terms, interpretation and explanation, and perform a "functional understanding" for "post-hoc interpretability", which is essentially focusing on the why a model predicts a certain abstract concept (e.g. a class category) after it has been trained and not while it is learning its representations.
The authors provide details of Activation Mapping and it's variants for Interpretation and 4 different techniques for explanation, Sensitivity Analysis, Simple Taylor Decomposition, Relevance Propagation and the LRP Explanation Framework. Each technique is explained with relevant visualizations, analogies and mathematically theory.
The paper also provides the practical tips to using LRP on one's own models, as well as defining techniques for quantitatively evaluating explanation techniques.  The paper concludes by providing real world examples of the use of model explanation for the tasks of model validation and scientific data analysis.
 
#### Strengths

1. The paper is very tutorial like and as such is a highly recommended read for someone new to the field of model interpretability.
2. The theory behind each technique is well explained and illustrates the intuition behind each technique well.
3. The tips and recommendations provided are something every researcher wishes they had when recreating a technique proposed in literature. This paper gives them to you.
 
#### Weaknesses

1. The paper claims to be model agnostic, however, quite a bit of the theory relies on specific model types (such as deep ReLU networks). Also, the process of not looking at the innards of a model seems counter-intuitive since CNNs, LSTMs and DBNs are inherently different in their formulation at a low level and one can possibly gain unique insight and perspective by taking that difference into account.
2. More examples per technique on different problem types (and not just classification) would have helped appeal to a wider audience.
3. Some parts of the activation mapping section seemed hand wavy.
 
#### Reflections

The paper is a vital one for gleaning insight into how DNNs work and how to best evaluate them even if strong metrics for evaluation of performance exist. Indeed, an example of this is provided in the paper. The authors describe each technique well and motivate their usage. The highlight of this paper is the section on practical considerations. This is the paper I would recommend to new researchers wanting to get into Deep Learning in general.