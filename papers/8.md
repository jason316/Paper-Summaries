## Sketch2Photo: Internet Image Montage. 

#### ACM SIGGRAPH ASIA 2009, ACM Transactions on Graphics. Tao Chen, Ming-Ming Cheng, Ping Tan, Ariel Shamir, Shi-Min Hu. 

This paper details a pipeline for generating photo realistic images from hand drawn sketches which are text labelled. The labels are used to perform image searches for the background and each scene item to get a set of candidate images which are then filtered based on saliency segmentation (which aids more towards blending than actual filtering), contour consistency of the segmentation and content consistency (which uses clustering to find similar images based on the appearance features). The major novelty of the paper is hybrid blending approach which works on super pixels classified as either M1 or M2 based on texture and color consistency. The categories are then used to calculate the optimal set of super pixels which will form the blending boundary and the improved Poisson blending is performed on pixels labelled M1 and alpha matte blending on pixels labelled M2. The blending cost is also used to rank the images in terms of composition quality before they are presented to the user.

Discussion:

1. The authors impose many constraints when doing background image search. Wouldn't they benefit from the method in Lalonde et al. in the case of cluttered backgrounds? They could have possibly tried adapting the method in Lalonde et al. to their pipeline and report results.

2. Their algorithm makes the assumption that scene items do not overlap "often". How would they handle overlapping of, suppose, multiple people in a crowded scene?

3. Why are the authors moving away from a completely automated system to one that requires user sketching and labelling to fine tune refinement? Doesn't that defeat the purpose of the motivations provided in a way?