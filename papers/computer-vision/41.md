## Beyond Skip Connections: Top-Down Modulations for Object Detection

#### Abhinav Shrivastava, Rahul Sukthankar, Jitendra Malik, Abhinav Gupta

In this paper, the authors attempt to tackle the problem of object detection for small objects by leveraging both the low level layers for capturing finer object details as well as the semantic understanding from the upper layers.

They propose the process of *top-down modulation*, where they leverage the semantic understanding of the upper layers to select and modulate what finer details of the lower layers to incorporate in the final representation. This technique supplements existing architectures and is thus applicable for all major architectures.

The basic idea is to have a network double back on itself in a U like formation, with the first half being the bottom-up features and the second half being the top-down features. The technique involves 2 new types of layers: a lateral module and a top-down module. The lateral module is responsible for taking in a bottom-up feature from a specific layer and producing the corresponding lateral feature. The top-down module combines the lateral feature from the connecting layer with the top-down features from the previous top-down layer, and also optionally upsample the feature map, thus forming a generalization of skip connections. The parameters of the network control the level of modulation, the output size, and the capacity of the network

A question could be how much influence the bottom-up layers exhibit on the top-down layers. The authors show a significant improvement with the lateral modules than without, but do not quantify which lateral modules influence the final result or even by how much. It is possible just a few parameters are proving useful and indentifying these could help in training the network.