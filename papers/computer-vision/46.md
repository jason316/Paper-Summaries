## Knowing When to Look: Adaptive Attention via A Visual Sentinel for Image Captioning

#### Jiasen Lu, Caiming Xiong, Devi Parikh, Richard Socher. IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2017

In this paper, the authors develop a mechanism for neural encoder-decoder image captioning systems to adaptively pick image features or the learned language representation of the decoder model when generating each word of the caption, so as to better model the difference between words which are visually distinct from words which aren't. The primary contribution of the paper is the "visual sentinel" of the LSTM which extracts a representation from the LSTM's hidden and memory states to be used when generating non-visual words of the caption. The model is able to pick between the spatial attention guided image features, a.k.a. the context vector, or the visual sentinel depending on the kind of word it wishes to output next, a visual one or non-visual one. This ability to adaptively choose is granted by the sentinel gate, which is an additional element in the context vector which is generated from the visual sentinel representation. Since it is a part of the context vector, the sentinel gate is also attended to, and depending on how much attention it receives at each time step, the model is able to decipher whether to use the context vector or the visual sentinel in the decoding process at that time step.

In formulating the visual sentinel and the sentinel gate, the authors utilize single layer networks to learn and transform the input vectors to generate the required vectors which are used as the latent representation in the visual sentinel or the gate value in the sentinel gate, thus leading to a data-driven approach akin to Xu et. al. The authors show empirically that their approach outperforms all state of the art methods across multiple metrics (BLEU-4, CIDEr, METEOR, ROUGE-L, and SPICE) on both the COCO captioning dataset as well as the Flickr30k dataset. This is shown via both offline analysis as well as results from the COCO evaluation server. A range of analyses on the outputs via the spatial attention map and the visual grounding probabilities validate that the model is learning a good representation of both image captioning as well as adaptive attention.


##### Strengths

1. The idea of being able to adaptively pick features based on the kind of word to be generated (visual or non-visual) serves as a great middle ground between models that are fed visual features only at the beginning versus models which receive image features at every time step. Thus conceptually, this idea is quite sound.
2. The approach of Xu et. al. gave us spatial attention maps for free to better understand and visualize what the model is doing. Similarly, this model provides us with visual grounding probabilities for free courtesy of the sentinel gate. This allows us to perform the weakly-supervised localization experiment to quantitatively evaluate whether the model is actually looking at the correct element in the image for which it is generating the word for. This is a poweful tool in my opinion and one that can lead to better understanding and improvements of attention models.
3. The authors use a data driven approach to learn the parameters for the visual sentinel and the sentinel gate. This is a good idea in my very personal opinion since now the model can learn from internet scale data as well as actively adapt itself to different specific tasks, such as human robot interaction. All that is needed is the right kind of dataset.


##### Weaknesses

1. The authors do not do an encoder comaprison to make an apples to apples comparison with the NIC and other models using Inception V3.
2. It is not clear from a theoretical perspective what the effect of the Sentinel residual layer is on the gradient health and whether the model would suffer from any type of gradient vanishing or explosion problem given that the network now has more hoops to jump through without any help from batch normalization or similar techniques.
3. Some of the design choices such as tanh or ReLU activations are not clearly explained.



##### Most Interesting Thought

An interesting idea would be to examine optimization strategies to help the model learn better sentinel representations. This could be via better objective functions or via novel training mechanisms. 
Additionally usage of techniques to encourage healthy gradient propagation as well as more explicit analysis of the design choices, such as experiments with activation layers or embedding models, could provide sufficient material for future work in this space.