## VQA: Visual Question Answering. 

#### S. Antol*, A. Agrawal*, J. Lu, M. Mitchell, D. Batra, C. L. Zitnick, and D. Parikh. ICCV, 2015. 

The paper proposes a new type of AI task that combines the different sub-branches of AI, Visual Question Answering. The idea is that given an image and a set of questions about that image, can a machine generate correct or plausible answers? The authors state that this task is significantly more challenging than image captioning since it requires much more high-level and more fine-grained knowledge about the image as well as better natural language understanding to generate the answers, while at the same time, the task is easier to evaluate than image captioning. This is due to the fact that most answers are 1-4 words long. The authors describe the collection of a new dataset based on MS COCO images and synthetic, abstract images that capture high-level information. Much emphasis is placed in collecting as diverse a set of questions and answers as possible and various analyses are performed to evaluate metrics such as diversity of words, type of questions and answers and the importance of the image and common sense when answering questions. Baseline techniques using deep learning are provided.