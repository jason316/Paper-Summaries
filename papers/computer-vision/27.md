## VQA: Visual Question Answering. 

#### S. Antol\*, A. Agrawal\*, J. Lu, M. Mitchell, D. Batra, C. L. Zitnick, and D. Parikh. ICCV, 2015. 

The paper proposes a new type of AI task that combines the different sub-branches of AI, Visual Question Answering. The idea is that given an image and a set of questions about that image, can a machine generate correct or plausible answers? The authors state that this task is significantly more challenging than image captioning since it requires much more high-level and more fine-grained knowledge about the image as well as better natural language understanding to generate the answers, while at the same time, the task is easier to evaluate than image captioning. This is due to the fact that most answers are 1-4 words long. The authors describe the collection of a new dataset based on MS COCO images and synthetic, abstract images that capture high-level information. Much emphasis is placed in collecting as diverse a set of questions and answers as possible and various analyses are performed to evaluate metrics such as diversity of words, type of questions and answers and the importance of the image and common sense when answering questions. Baseline techniques using deep learning are provided.


#### Strengths

1. This is a large scale dataset, allowing for many modern learning algorithms to leverage the size and diversity of the Images, Questions and Answers in order to learn meaningful representations without resorting to relatively fragile techniques such as transfer learning.
2. Amazing analysis of question-answer pairs. The nicest things about this paper is how the authors through user studies and visualizations thoroughly analyze various properties of the dataset. This helps build confidence in the dataset and encourages researchers to look into this area.
3. Plenty of baseline implementations to help give a sense of possible approaches.
4. The abstract scenes dataset allows researchers from non-vision backgrounds (such as linguistics, HRI and neuro-science) to delve into this task.

#### Weaknesses

1. The baseline methods use different splits for machine accuracies and human accuracies. This does not lend itself to a fair comparison and no particular justification is given for this design choice.
2. The distribution of questions and answers, while diverse is quite skewed towards certain questions. In hindsight, this is now addressed in the VQA 2.0 dataset but it was still a weakness when the paper first came out.


#### Interesting Thought

Since this is the paper that established the field of VQA, whatever interesting thought I may have may already be a published paper. However, in the introduction, the paper mentions the use of Computer Vision, Natural Language Processing and "Knowledge Representations". We have seen ample work using fancy architectures and techniques to tackle the pillars of CV and NLP, but the theory of using Knowledge Representations is still nascent and is beginning to see active interest.

Another important task that the VQA dataset enables is active learning, where the system refers to a human to answer a question in order to improve its own performance. This field is also receiving significant attention and it would be interesting to put together a survey of active learning papers that use VQA as a type of apriori.